{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhập data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fasttext\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy\n",
    "from num2words import num2words \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('topic_detection_train.v1.0.txt', newline=None, encoding='utf-8')\n",
    "# data = open('__label__tai_chinh.txt', newline=None, encoding='utf-8')\n",
    "data.read()\n",
    "data.seek(0)\n",
    "lines = data.readlines()\n",
    "lowercaseLines = list(map(lambda line: line.lower(), lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesWithoutLinks = list(map(lambda line: re.sub(r\"https?\\s*:\\s*\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,4}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", '', line), lowercaseLines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesFormattedDot = list(map(lambda line: re.sub(r\"\\s*\\.+\\s*(\\.*\\s*){100}\", ' punc ', line), linesWithoutLinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesWithoutWierdChar = list(map(lambda line: re.sub(r'[\\W]+', ' ', line), linesFormattedDot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "formattedLines = list(map(lambda line: line.replace('\\n', '').split(\" \", 1), linesWithoutWierdChar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(formattedLines, columns=['label', 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = df['content'].tolist();\n",
    "linesWithoutUnderScores = list((map(lambda line: re.sub(r'_+', ' ', line), datalist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_brief_char_to_word(matchobj):\n",
    "    string = matchobj.group(0)\n",
    "    foundNum = re.findall('\\d+', string);\n",
    "    result = string\n",
    "    if len(foundNum) > 0:\n",
    "        num = foundNum[0]\n",
    "        left = \" \" + foundNum[1] + \" \" if len(foundNum) > 1 else \"\"\n",
    "        result = num\n",
    "        if len(num) < len(string):\n",
    "            char = string[len(num):len(string)] if left == \"\" else string[len(num):len(string) - len(left) + 2]\n",
    "            obj = {\n",
    "                'đ': 'đồng',\n",
    "                'k': 'nghìn',\n",
    "                'tr': 'triệu',\n",
    "                'h': 'giờ',\n",
    "                'm': 'mét',\n",
    "                'm²': 'mét vuông',\n",
    "                'pn': 'phòng ngủ',\n",
    "            }\n",
    "            if obj.get(char) != None:\n",
    "                result += \" \" + obj.get(char) + left\n",
    "            else:\n",
    "                result += \" \" + char + left\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splittedNumAndWordLines = list((map(lambda line: re.sub(r'\\d*[a-zđ²]+\\d*', convert_brief_char_to_word,line), linesWithoutUnderScores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_num_to_word(matchobj):\n",
    "    num = matchobj.group(0)\n",
    "    if len(num) > 7 or num[0] == '0':\n",
    "        num = \" \".join(list(map(lambda char: num2words(int(char), lang='vi'),list(num))))\n",
    "        return num;\n",
    "    return num2words(int(num), lang='vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2wordsLines = list((map(lambda line: re.sub(r'\\d+', convert_num_to_word,line), splittedNumAndWordLines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removedOneWordLines = list((map(lambda line: re.sub(r'\\s+\\w\\s+', \" \",line), num2wordsLines)))\n",
    "removedOneWordLines = list((map(lambda line: re.sub(r'\\s+\\w\\s+', \" \",line), linesWithoutUnderScores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords(documents, threshold=3):\n",
    "    \"\"\"\n",
    "    :param documents: list of documents\n",
    "    :param threshold:\n",
    "    :return: list of words has idf <= threshold\n",
    "    \"\"\"\n",
    "    tfidf = TfidfVectorizer(min_df=100)\n",
    "    tfidf_matrix = tfidf.fit_transform(documents)\n",
    "    features = tfidf.get_feature_names()\n",
    "    stopwords = []\n",
    "    print(min(tfidf.idf_), max(tfidf.idf_), len(features))\n",
    "    for index, feature in enumerate(features):\n",
    "        if tfidf.idf_[index] <= threshold:\n",
    "            stopwords.append(feature)\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = get_stopwords(df['content'], threshold=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manual_stopwords.txt', 'w', encoding='utf8') as fp:\n",
    "        for word in stopwords:\n",
    "            fp.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('stopwords.txt', newline=None, encoding='utf-8')\n",
    "lines.read()\n",
    "lines.seek(0)\n",
    "stopwords = lines.readlines()\n",
    "stopwords = list(map(lambda line: line.replace('\\n', ''), stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeff'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.pop(0)\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesWithoutStopwords = list(map(lambda line: \" \".join(list(filter(lambda word: stopwords.count(word) == 0, line.split(\" \")))), removedOneWordLines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = linesWithoutStopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "for label, content in zip(list(df['label']), list(df['content'])):\n",
    "  if files.get(label) == None:\n",
    "    files[label] = []\n",
    "  files[label].append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in files.keys():\n",
    "  store_file(label + '.txt', files[label], len(files[label]) * [label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = [[], [], [], []]\n",
    "for label in files.keys():\n",
    "    if \"__label__tai_chinh, __label__kinh_doanh_va_cong_nghiep\".count(label):\n",
    "        x_tr, x_te, y_tr, y_te = train_test_split(files[label], len(files[label]) * [label], test_size=0.4, random_state=0)        \n",
    "    else:\n",
    "        x_tr, x_te, y_tr, y_te = train_test_split(files[label], len(files[label]) * [label], test_size=0.4, random_state=0)\n",
    "    X_train.extend(x_tr)\n",
    "    X_test.extend(x_te)\n",
    "    y_train.extend(y_tr)\n",
    "    y_test.extend(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_file('created_train.txt', X_train, y_train)\n",
    "store_file('created_test.txt', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn k-fold cross validation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['label'], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_file('created_train.txt', X_train.tolist(), y_train.tolist())\n",
    "store_file('created_test.txt', X_test.tolist(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator for fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasttextEstimator(BaseEstimator):\n",
    "\n",
    "    def __init__(self, model_dir):\n",
    "        self.model_dir = model_dir\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        \"\"\"\n",
    "        Train fasttext on the given features and labels.\n",
    "        :param features: a list of documents.\n",
    "        :param labels: the list of labels associated with the list of features.\n",
    "        \"\"\"\n",
    "        store_file(os.path.join(self.model_dir, \"train.txt\"), features, labels)\n",
    "        fasttext.train_supervised(input=os.path.join(self.model_dir, \"train.txt\"),\n",
    "                                  epoch=6, lr=1.0, wordNgrams=2, verbose=1, minCount=1, loss='hs', thread=4).save_model('cv_model.bin')\n",
    "        self.model = fasttext.load_model(os.path.join(self.model_dir, \"cv_model.bin\"))\n",
    "        return self\n",
    "\n",
    "    def score(self, features, labels):\n",
    "        \"\"\"\n",
    "        Compute the macro-f1 score for the predictions on the given features.\n",
    "        :param features: a list of documents.\n",
    "        :param labels: the list of labels associated with the list of features.\n",
    "        :return: f1_score: the macro-f1 score for the predictions on the given features.\n",
    "        \"\"\"\n",
    "        predicted_labels = []\n",
    "        for feature in features:\n",
    "            prediction = self.model.predict(feature)\n",
    "            predicted_label = prediction[0]\n",
    "            predicted_labels.append(predicted_label)\n",
    "        return f1_score(labels, predicted_labels, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_file(output_file, features, labels):\n",
    "    \"\"\"Write the training data in fasttext format to disk.\n",
    "    :param output_file: the name of the output file.\n",
    "    :param features: the features, a list of strings.\n",
    "    :param labels: the labels associated with features.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', newline='\\n', encoding='utf-8') as f:\n",
    "        for i in range(0, len(features)):\n",
    "            f.write(\"%s %s\\n\" % (labels[i], features[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fasttext library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = fasttext.train_supervised(input='created_train.txt', autotuneValidationFile='created_test.valid')\n",
    "# model.save_model('cv_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(\"cv_model.bin\")\n",
    "model.test('created_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.('mùa thứ nhất')\n",
    "estimator = FasttextEstimator(model_dir='C:/Users/Dung/Desktop/python/My python note/')\n",
    "cross_val_score(estimator, df['content'].tolist(), df['label'].tolist(), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = fasttext.load_model(\"cv_model.bin\")\n",
    "# model.get_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer(max_features=5000)),\n",
    "     ('tfidf', TfidfTransformer(sublinear_tf=True, use_idf=True)),\n",
    "     ('clf', SGDClassifier(loss='log', penalty='l2')),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=3, refit = True, iid=False, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=5000,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=None,\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'clf__alpha': [1e-07, 1e-06, 1e-05, 0.0001, 0.001,\n",
       "                                        0.01, 0.1, 1.0],\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.0001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gs_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87015625"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(predicted == y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                   __label__chinh_tri       0.96      0.99      0.97       341\n",
      "         __label__con_nguoi_va_xa_hoi       0.95      0.97      0.96       161\n",
      "               __label__cong_nghe_moi       0.00      0.00      0.00        13\n",
      "            __label__do_an_va_do_uong       0.97      0.99      0.98       948\n",
      "                     __label__du_lich       0.98      0.96      0.97       366\n",
      "                    __label__giai_tri       0.97      1.00      0.99        74\n",
      "                    __label__giao_duc       0.92      0.96      0.94       269\n",
      "                  __label__giao_thong       1.00      0.86      0.93        37\n",
      "                    __label__khoa_hoc       0.96      0.83      0.89        65\n",
      "   __label__kinh_doanh_va_cong_nghiep       0.61      0.74      0.67       950\n",
      "         __label__lam_dep_va_the_hinh       0.99      0.92      0.95       125\n",
      " __label__mang_internet_va_vien_thong       0.99      0.97      0.98       233\n",
      "__label__may_tinh_va_thiet_bi_dien_tu       0.99      0.88      0.93        88\n",
      "                     __label__mua_sam       0.92      0.96      0.94       466\n",
      "                  __label__nghe_thuat       1.00      0.99      0.99       245\n",
      "                     __label__nha_dat       0.96      0.99      0.98      1027\n",
      "                 __label__nha_va_vuon       1.00      0.88      0.94       103\n",
      "                   __label__phap_luat       1.00      0.73      0.84        37\n",
      "                        __label__sach       0.99      0.94      0.97       155\n",
      "        __label__suc_khoe_va_benh_tat       0.93      0.74      0.82        73\n",
      "                   __label__tai_chinh       0.38      0.25      0.30       522\n",
      "                    __label__the_thao       1.00      0.76      0.86        33\n",
      "       __label__thoi_quen_va_so_thich       1.00      0.83      0.90        69\n",
      "\n",
      "                             accuracy                           0.87      6400\n",
      "                            macro avg       0.89      0.83      0.86      6400\n",
      "                         weighted avg       0.86      0.87      0.86      6400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dung\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix =  metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_y_train = []\n",
    "outlier_x_train = []\n",
    "outlier_y_test = []\n",
    "outlier_x_test = []\n",
    "\n",
    "outliers = \", \".join(['__label__cong_nghe_moi','__label__tai_chinh', '__label__kinh_doanh_va_cong_nghiep'])\n",
    "\n",
    "for label, content in zip(y_train, X_train):\n",
    "    if outliers.count(label) == 1:\n",
    "        outlier_y_train.append(label)\n",
    "        outlier_x_train.append(content)\n",
    "for label, content in zip(y_test, X_test):\n",
    "    if outliers.count(label) == 1:\n",
    "        outlier_y_test.append(label)\n",
    "        outlier_x_test.append(content)\n",
    "temp_y_train = ['__label__outlier' if outliers.count(label) else label\n",
    "               for label in y_train]\n",
    "temp_y_test = ['__label__outlier' if outliers.count(label) else label\n",
    "               for label in y_test]\n",
    "store_file('outlier_train.txt', outlier_x_train, outlier_y_train)\n",
    "store_file('outlier_test.txt', outlier_x_test, outlier_y_test)\n",
    "store_file('train_temp.txt', X_train.tolist(), temp_y_train)\n",
    "store_file('test_temp.txt', X_test.tolist(), temp_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "     ('tfidf', TfidfTransformer(sublinear_tf=True, use_idf=True)),\n",
    "     ('clf', SGDClassifier(loss='log', penalty='l2', alpha=1e-3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=5000, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='log',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, temp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                   __label__chinh_tri       0.97      0.86      0.91       341\n",
      "         __label__con_nguoi_va_xa_hoi       0.99      0.86      0.92       161\n",
      "            __label__do_an_va_do_uong       0.92      0.98      0.95       948\n",
      "                     __label__du_lich       0.98      0.86      0.91       366\n",
      "                    __label__giai_tri       1.00      0.92      0.96        74\n",
      "                    __label__giao_duc       0.94      0.76      0.84       269\n",
      "                  __label__giao_thong       1.00      0.08      0.15        37\n",
      "                    __label__khoa_hoc       0.00      0.00      0.00        65\n",
      "         __label__lam_dep_va_the_hinh       1.00      0.45      0.62       125\n",
      " __label__mang_internet_va_vien_thong       1.00      0.90      0.95       233\n",
      "__label__may_tinh_va_thiet_bi_dien_tu       1.00      0.68      0.81        88\n",
      "                     __label__mua_sam       0.89      0.89      0.89       466\n",
      "                  __label__nghe_thuat       1.00      0.98      0.99       245\n",
      "                     __label__nha_dat       0.91      0.97      0.94      1027\n",
      "                 __label__nha_va_vuon       1.00      0.52      0.69       103\n",
      "                     __label__outlier       0.72      0.98      0.83      1485\n",
      "                   __label__phap_luat       0.00      0.00      0.00        37\n",
      "                        __label__sach       1.00      0.66      0.79       155\n",
      "        __label__suc_khoe_va_benh_tat       1.00      0.15      0.26        73\n",
      "                    __label__the_thao       0.00      0.00      0.00        33\n",
      "       __label__thoi_quen_va_so_thich       1.00      0.20      0.34        69\n",
      "\n",
      "                             accuracy                           0.87      6400\n",
      "                            macro avg       0.82      0.61      0.65      6400\n",
      "                         weighted avg       0.87      0.87      0.85      6400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dung\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions_SGD = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(temp_y_test,predictions_SGD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect_outlier = TfidfVectorizer(max_features=1000, ngram_range=(1,2), max_df=0.5, sublinear_tf=True)\n",
    "Tfidf_vect_outlier.fit(outlier_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_true_x_test = []\n",
    "outlier_true_y_test = []\n",
    "x_list = X_test.tolist()\n",
    "y_list = y_test.tolist()\n",
    "# for content in X_test.tolist():\n",
    "#     if outlier_x_test.count(content) == 1:\n",
    "#         index = outlier_x_test.index(content)\n",
    "#         outlier_true_x_test.append(outlier_x_test[index])\n",
    "#         outlier_true_y_test.append(outlier_y_test[index])\n",
    "for index, label in enumerate(predictions_SGD):\n",
    "    if label == '__label__outlier':\n",
    "        outlier_true_x_test.append(x_list[index])\n",
    "        outlier_true_y_test.append(y_list[index])   \n",
    "store_file('outlier_true_test.txt', outlier_true_x_test, outlier_true_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_X_outlier_Tfidf = Tfidf_vect_outlier.transform(outlier_x_train)\n",
    "# Test_X_outlier_Tfidf = Tfidf_vect_outlier.transform(outlier_true_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_outlier_clf = Pipeline([\n",
    "     ('vect', CountVectorizer(ngram_range=(1,1))),\n",
    "     ('tfidf', TfidfTransformer(sublinear_tf=True, use_idf=True)),\n",
    "     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42, tol=None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=None, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_outlier_clf.fit(outlier_x_train, outlier_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                   __label__chinh_tri       0.00      0.00      0.00         4\n",
      "         __label__con_nguoi_va_xa_hoi       0.00      0.00      0.00         1\n",
      "               __label__cong_nghe_moi       0.00      0.00      0.00         8\n",
      "            __label__do_an_va_do_uong       0.00      0.00      0.00         1\n",
      "                     __label__du_lich       0.00      0.00      0.00         5\n",
      "                    __label__giao_duc       0.00      0.00      0.00        18\n",
      "                  __label__giao_thong       0.00      0.00      0.00         3\n",
      "                    __label__khoa_hoc       0.00      0.00      0.00         5\n",
      "   __label__kinh_doanh_va_cong_nghiep       0.59      0.89      0.71       916\n",
      "         __label__lam_dep_va_the_hinh       0.00      0.00      0.00         1\n",
      " __label__mang_internet_va_vien_thong       0.00      0.00      0.00         5\n",
      "__label__may_tinh_va_thiet_bi_dien_tu       0.00      0.00      0.00        11\n",
      "                     __label__mua_sam       0.00      0.00      0.00        14\n",
      "                     __label__nha_dat       0.00      0.00      0.00        13\n",
      "                 __label__nha_va_vuon       0.00      0.00      0.00         3\n",
      "                   __label__phap_luat       0.00      0.00      0.00        19\n",
      "                        __label__sach       0.00      0.00      0.00         3\n",
      "                   __label__tai_chinh       0.36      0.11      0.17       516\n",
      "                    __label__the_thao       0.00      0.00      0.00         2\n",
      "       __label__thoi_quen_va_so_thich       0.00      0.00      0.00         2\n",
      "\n",
      "                             accuracy                           0.56      1550\n",
      "                            macro avg       0.05      0.05      0.04      1550\n",
      "                         weighted avg       0.47      0.56      0.48      1550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dung\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions_SGD_outlier = text_outlier_clf.predict(outlier_true_x_test)\n",
    "print(metrics.classification_report(outlier_true_y_test,predictions_SGD_outlier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(Tfidf_vect_outlier.vocabulary_, reverse=True)\n",
    "Tfidf_vect_outlier.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_SGD_outlier = predictions_SGD_outlier.tolist()\n",
    "predictions = []\n",
    "for label in predictions_SGD:\n",
    "    if label == '__label__outlier':\n",
    "        predictions.append(predictions_SGD_outlier.pop(0))\n",
    "    else:\n",
    "        predictions.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                   __label__chinh_tri       0.95      0.98      0.96       341\n",
      "         __label__con_nguoi_va_xa_hoi       0.93      0.98      0.95       161\n",
      "               __label__cong_nghe_moi       1.00      0.15      0.27        13\n",
      "            __label__do_an_va_do_uong       0.96      1.00      0.98       948\n",
      "                     __label__du_lich       0.96      0.94      0.95       366\n",
      "                    __label__giai_tri       0.96      1.00      0.98        74\n",
      "                    __label__giao_duc       0.92      0.91      0.92       269\n",
      "                  __label__giao_thong       1.00      0.68      0.81        37\n",
      "                    __label__khoa_hoc       0.95      0.63      0.76        65\n",
      "   __label__kinh_doanh_va_cong_nghiep       0.59      0.86      0.70       950\n",
      "         __label__lam_dep_va_the_hinh       1.00      0.92      0.96       125\n",
      " __label__mang_internet_va_vien_thong       0.97      0.97      0.97       233\n",
      "__label__may_tinh_va_thiet_bi_dien_tu       1.00      0.86      0.93        88\n",
      "                     __label__mua_sam       0.93      0.93      0.93       466\n",
      "                  __label__nghe_thuat       0.99      1.00      0.99       245\n",
      "                     __label__nha_dat       0.95      0.98      0.97      1027\n",
      "                 __label__nha_va_vuon       0.99      0.84      0.91       103\n",
      "                   __label__phap_luat       1.00      0.19      0.32        37\n",
      "                        __label__sach       0.99      0.94      0.96       155\n",
      "        __label__suc_khoe_va_benh_tat       0.96      0.71      0.82        73\n",
      "                   __label__tai_chinh       0.36      0.11      0.17       522\n",
      "                    __label__the_thao       1.00      0.64      0.78        33\n",
      "       __label__thoi_quen_va_so_thich       1.00      0.80      0.89        69\n",
      "\n",
      "                             accuracy                           0.86      6400\n",
      "                            macro avg       0.93      0.78      0.82      6400\n",
      "                         weighted avg       0.85      0.86      0.84      6400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext.train_supervised(input='outlier_train.txt', maxn=0, minn=0, bucket=785249, neg=5, ws=5, dim=53,\n",
    "                                  epoch=2, lr=1.0, wordNgrams=5, verbose=2, minCount=1, loss='softmax', thread=4).save_model('cv_model_outlier.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = fasttext.load_model(\"cv_model_outlier.bin\")\n",
    "model.test_label('outlier_true_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
